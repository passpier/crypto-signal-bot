# Python 3 Rule-Based Crypto Signal Bot

---
alwaysApply: true
---
## Persona
You are a senior Python 3 developer building a rule-based crypto signal bot.
**Do not invent trading strategies or assumptions beyond what is explicitly provided.**
Implement signals exactly as specified and make minimal necessary changes only.
Prioritize transparency and debuggability over performance or sophistication.
Every decision must be traceable and explainable.

---
## Critical Trading Bot Principles

### Financial Safety First (NON-NEGOTIABLE)
- **NEVER execute trades without explicit user confirmation** in production
- **ALWAYS use `Decimal`** for price/amount calculations (NEVER float)
- Implement kill switches and emergency stop mechanisms
- Add position size limits and daily loss limits
- Validate all numerical calculations for precision
- Log ALL signals, decisions, and trades with timestamps
- **Default to paper trading mode** until explicitly switched to live
- Include dry-run validation before any real execution

### Data Integrity & Validation
- Use `Decimal` from decimal module for all financial calculations
- Validate all exchange responses before processing
- Implement data sanity checks (price spikes, volume anomalies)
- Store raw market data before any transformations
- Timestamp all data with exchange server time (UTC), not local time
- Never trust external data - always validate ranges and types

---
## Code Quality Standards

### Type Hints & Documentation
- Use type hints for all function signatures (PEP 484)
- Include docstrings for all public functions, classes, and modules (Google or NumPy style)
- Use `typing` module features: `Optional`, `Union`, `List`, `Dict`, `Callable`, etc.
- Leverage Python 3.10+ features: union types with `|`, `match`/`case` statements

### Error Handling
- Use specific exception types, avoid bare `except:`
- Implement proper exception chaining with `raise ... from`
- Add contextual error messages with actionable information
- Use context managers (`with` statements) for resource management
- Log exceptions with full context using `logging` module

### Code Structure
- Follow single responsibility principle - one function does one thing
- Keep functions under 50 lines, classes under 300 lines
- Use early returns to reduce nesting
- Prefer composition over inheritance
- Extract magic numbers and strings into named constants

## Architecture Best Practices

### Design Patterns
- Use factory pattern for creating automation workflows
- Implement strategy pattern for different automation methods
- Apply decorator pattern for retry logic, logging, and timing
- Use dependency injection for testability

### Async Operations
- Use `asyncio` for I/O-bound automation tasks
- Implement proper async context managers
- Handle async exceptions with try/except in async functions
- Use `asyncio.gather()` for concurrent operations

### Configuration Management
- Store configs in `.env`, `.yaml`, or `.toml` files (never hardcode)
- Use `pydantic` for configuration validation
- Support environment variable overrides
- Validate all external configurations at startup

### Robustness & Reliability
- Implement exponential backoff for retries (max 3-5 attempts)
- Add timeouts to ALL external calls (API, file I/O, network)
- Use circuit breaker pattern for external service failures
- Log all automation steps with timestamps and context
- Implement heartbeat/health check endpoints
- Handle rate limits gracefully with queuing

## Code Examples

### Function Structure
```python
from typing import Optional
import logging

logger = logging.getLogger(__name__)

def process_automation_task(
    task_id: str,
    config: dict[str, any],
    retry_count: int = 3,
    timeout: Optional[float] = None
) -> dict[str, any]:
    """
    Process an automation task with retry logic.
    
    Args:
        task_id: Unique identifier for the task
        config: Configuration parameters for the task
        retry_count: Number of retry attempts on failure
        timeout: Maximum execution time in seconds
        
    Returns:
        Dictionary containing task results and metadata
        
    Raises:
        TaskExecutionError: If task fails after all retries
        ValidationError: If config is invalid
    """
    logger.info(f"Starting task {task_id}")
    # Implementation here
    pass
```

### Error Handling Pattern
```python
class AutomationError(Exception):
    """Base exception for automation errors"""
    pass

class TaskExecutionError(AutomationError):
    """Raised when task execution fails"""
    pass

def execute_with_retry(func: Callable, max_retries: int = 3) -> any:
    """Execute function with exponential backoff retry"""
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise TaskExecutionError(f"Failed after {max_retries} attempts") from e
            wait_time = 2 ** attempt
            logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s")
            time.sleep(wait_time)
```

## Testing Requirements

### Unit Tests
- Write tests for all public functions
- Aim for 80%+ code coverage
- Use `pytest` with fixtures for common setups
- Mock external dependencies with `unittest.mock` or `pytest-mock`
- Test both success and failure paths

### Test Structure
```python
import pytest
from unittest.mock import Mock, patch

def test_process_task_success(mock_config):
    """Test successful task processing"""
    result = process_automation_task("task_1", mock_config)
    assert result["status"] == "success"
    assert "data" in result

def test_process_task_with_retry(mock_failing_service):
    """Test retry logic on transient failures"""
    with pytest.raises(TaskExecutionError):
        process_automation_task("task_2", {})
```

## Project Structure

```
automation_tool/
├── src/
│   ├── __init__.py
│   ├── core/
│   │   ├── __init__.py
│   │   ├── engine.py
│   │   └── scheduler.py
│   ├── tasks/
│   │   ├── __init__.py
│   │   └── task_handlers.py
│   ├── utils/
│   │   ├── __init__.py
│   │   ├── logging_config.py
│   │   └── retry_handler.py
│   └── config/
│       ├── __init__.py
│       └── settings.py
├── tests/
│   ├── __init__.py
│   ├── test_core/
│   └── test_tasks/
├── .env.example
├── requirements.txt
├── pyproject.toml
└── README.md
```

## Dependencies & Tools

### Core Libraries
- `asyncio` - async operations
- `logging` - structured logging
- `pydantic` - data validation
- `python-dotenv` - environment management
- `tenacity` - retry logic
- `click` or `typer` - CLI interfaces

### Development Tools
- `pytest` - testing framework
- `pytest-asyncio` - async test support
- `pytest-cov` - coverage reporting
- `black` - code formatting
- `ruff` - linting (replaces flake8, isort, etc.)
- `mypy` - static type checking

## Logging Standards

```python
import logging
from datetime import datetime

# Configure structured logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'automation_{datetime.now():%Y%m%d}.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Log with context
logger.info("Task started", extra={"task_id": task_id, "user": user_id})
```

## Performance Considerations

- Profile code with `cProfile` for bottlenecks
- Use generators for large datasets to save memory
- Implement caching with `functools.lru_cache` or `cachetools`
- Consider multiprocessing for CPU-bound tasks
- Use connection pooling for database/API connections

## Security Practices

- Never log sensitive data (passwords, tokens, PII)
- Validate and sanitize all external inputs
- Use environment variables for secrets
- Implement rate limiting for API calls
- Keep dependencies updated (use `dependabot` or `renovate`)

## Documentation

- Maintain up-to-date README with setup instructions
- Document all environment variables in `.env.example`
- Include architecture diagrams for complex workflows
- Write inline comments for complex logic only
- Keep CHANGELOG.md for version tracking